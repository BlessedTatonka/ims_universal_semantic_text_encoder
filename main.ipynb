{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2e4f0a",
   "metadata": {},
   "source": [
    "**Возникшие вопросы**\n",
    "   1. Почему в задании указано, что необходимо выбрать *датасеты*, а в примерах *бенчмарки*? При использовании бенчмарков теряется весь смысл задания, ведь они уже содержат множество датасетов и метрик с описаниями. \n",
    "   \n",
    "**План проекта**\n",
    "   1. Выбор датасетов.\n",
    "   \n",
    "   2. Определение метрик.\n",
    "   \n",
    "   3. Выбор подходов для сравнения.\n",
    "   \n",
    "   4. Постановка гипотез.\n",
    "   \n",
    "   5. Проведение экспериментов.\n",
    "   \n",
    "   6. Выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416024e8",
   "metadata": {},
   "source": [
    "### Датасеты:\n",
    "+ Параллельный перевод для удмуртского языка (как языка малой народности) [UDM](https://huggingface.co/datasets/udmurtNLP/flores-250-rus-udm).\n",
    "+ Парафразы [PAR](https://huggingface.co/datasets/merionum/ru_paraphraser). Кроме того, содержит \"непарафразы\", что также можно использовать для проверки качества.\n",
    "+ Всегда актуальная токсичность [TOX](https://huggingface.co/datasets/FredZhang7/toxi-text-3M). Я выбрал именно этот датасет, так как он содержит 50+ языков, и это наибльшая выборка для этой задачи, которую я сумел найти. В ней слишком много английского, турецкого и арабского. \n",
    "+ Суммаризация [SUM](https://huggingface.co/datasets/embedding-data/sentence-compression). В этом датасете тексты относительно небольшие и не требуют больших вычислительных мощностей.\n",
    "+ Мультиклассовая классификация [MGP](https://huggingface.co/datasets/datadrivenscience/movie-genre-prediction). Модель с описанием фильмов и жанрами.\n",
    "| Датасет | Размер* | Число языков |\n",
    "|----------|----------|----------|\n",
    "| flores-250-rus-udm    | 250   | 2   |\n",
    "| ru_paraphraser    | 7227   | 1   |\n",
    "| instructor-base    | 37910   | 45   |\n",
    "|sentence-compression |     2000     |     1       |\n",
    "|movie-genre-prediction |     54000        |   1      |\n",
    "\n",
    "### Метрики:\n",
    "+ *UDM* - косинусная близость русских и удмуртских эмбеддингов. Универсальный энкодер должен хорошо справляться не только с широко представленными языками и успешно извлекать смыслы из всего, что ему передают.\n",
    "+ *PAR* - считаем косинусную близость для пар с классом \"precise paraphrases\" и (1 - косинусная близость) для пар с классом \"non-paraphrases\". Класс \"near paraphrases\" игнорируем. Метрика, в какой-то степени, дополняет метрику *UDM*, показывая, что модель не просто располагает все эмбеддинги в одной точки векорного пространства.\n",
    "+ *SUM* - косинусная близость эмбеддингов текста и краткого изложения. Хотим знать, насколько хорошо модель справляется с извлечением смысла из больших текстов.\n",
    "+ *TOX* - произведение средней точности KNN** и энтропии точностей по классам (по языкам) $A \\cdot entropy([a_1, a_2, \\ldots, a_n]), a_i = acc_{c_i}$. Метрика показывает, насколько хорошо подель справляется с бинарной классификацией. Если не дополнять вычисления энтропией, то при использовании модели в дальнейшем на каком-то языке модель может показать результат, гораздо ниже ожидаемого. Текущая метрика будет сильно ниже, если модель справляется с предсказаниями на каких-то отдельных языках хуже, чем на других.\n",
    "+ *MGP* - f1_score macro на предсказания KNN. Проверка на задаче мультиклассовой классификации.\n",
    "\n",
    "### Подходы:\n",
    "+ *Word2Vec* - бейзлайн и наиболее примитивный подход. Для получения эмбеддингов предложения, буду брать усреднение по эмбеддингам слов. Я взял веса от предобученной модели [*glove-twitter-25*](https://radimrehurek.com/gensim/models/word2vec.html#other-embeddings).\n",
    "+ *T5-flan* [google/flan-t5-small](https://huggingface.co/google/flan-t5-small)  Использую усреднение эмбеддингов энкодера, так как в [этой статье](https://arxiv.org/abs/2108.08877) такой подход показал лучший результат для zero-shot. Модель обучалась на достаточно большом корпусе языков.\n",
    "+ [*InstructOR*](https://arxiv.org/pdf/2212.09741.pdf) - ещё одна T5-based модель, которая обучалась на каком-то невероятно большом корпусе данных и различных задач специально для создания векторных представлений.\n",
    "+ multilingual-e5-small ##############\n",
    "+ sentence-transformers/all-MiniLM-L6-v2 ##############\n",
    "+ Labse ##############\n",
    "\n",
    "| Модель | Вес | На скольки языках обучена  |\n",
    "|----------|----------|----------|\n",
    "| glove-twitter-25              | 110 MB   | 1   |\n",
    "| google/flan-t5-small          | 308 MB   | 50+   |\n",
    "| hkunlp/instructor-base        | 439 MB   | ?   |\n",
    "|intfloat/multilingual-e5-small |     471 MB     |     90+       |\n",
    "| all-MiniLM-L6-v2              |     91 MB        |   1      |\n",
    "| setu4993/LaBSE                | **1.88 GB**| **109** |\n",
    "\n",
    "### Гипотезы:\n",
    "+ Word2Vec покажет себя хуже всего в среднем по всем метрикам, так как не предназначен для задачи создания векторных представлений текста.\n",
    "+ Лучше всего себя покажет LaBSE, она содержит наибольшее число параметров и обучена на наибольшем количестве задач.\n",
    "+ Модель InstructOR покажет себя лучше, чем T5-flan, так как они имеют схожую архитектуру, но она была обучена специально для задачи получения векторных представлений и испытана на широком классе задач. Но, я не смог найти, какое число языков было в обучающей выборке. У google/flan-t5-small это значение достаточно велико.\n",
    "\n",
    "### Реализация:\n",
    "В папке *src* находятся следующие файлы:\n",
    "+ *data_processors.py* - содержит классы для каждого датасета. \n",
    "+ *model_processors.py* - для каждого типа модели свой класс-обертка, чтобы можно было использовать общий пайплайн. При этом можно заменять модели на более большие, но в текущих экспериментах я старался брать наименьшие.\n",
    "+ *metrics.py* - файл с методами, для расчета итоговых метрик.\n",
    "+ *utils.py* - дополнительные методы.\n",
    "\n",
    "Более подробное описание классов и методов есть в коде.\n",
    "\n",
    "### Результаты:\n",
    "\n",
    "| Модель | UDM | PAR | SUM | TOX | MGP |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| glove-twitter-25              |    |    |     |     |     | \n",
    "| google/flan-t5-small          |    |    |    |     |     | \n",
    "| hkunlp/instructor-base        |    |    |    |     |     | \n",
    "|intfloat/multilingual-e5-small |    |    |    |     |     | \n",
    "| all-MiniLM-L6-v2              |    |    |    |     |     | \n",
    "| setu4993/LaBSE                |    |    |    |     |     | \n",
    "\n",
    "------\n",
    "\n",
    "**Несколько уточнений по-поводу датасетов:*\n",
    "1. *Если данные поделены на train/test/val, я оставляю только train.*\n",
    "\n",
    "2. *Часть данных в не parquet формате я перевёл в parquet для ускорения.*\n",
    "\n",
    "3. *Я уменьшил размер toxi-text-3M с 2880667 до 37910 семплов. Ограничился 1000 семплов сверху и 100 снизу для каждого языка. Сверху, чтобы я успел провести эксперименты, а снизу, чтобы рассчеты среднего по языкам были более репрезентативны. Для возможности воспроизвести вычисления, файл с обновленным датасетом я добавлю в репозиторий. Кроме того, в ноутбуке **toxic_dataset_preparation.ipynb** находится полный процесс изменения датасета.* \n",
    "\n",
    "4. Датасет *sentence_compression* состоит из 180000 семплов, однако большие тексты требуют слишком много времени для вычисления, я ограничился 2000 семплов.\n",
    "\n",
    "\n",
    "***Во всех метриках я испольхую KNN с параметрами: n_neighbors=11, weights='distance', metric='cosine'. Основательно параметры я не подбирал, кроме числа соседей, в остальном - интуиция.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a215bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from src.data_processors import *\n",
    "from src.model_processors import *\n",
    "from src.metrics import *\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {DEVICE}')\n",
    "\n",
    "# Можно изменять порядок и добавлять модели с иным числом весов\n",
    "def get_models_tokenizers_processors():\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "    model_processor = T5ModelProcessor(model, tokenizer, device=DEVICE)\n",
    "    yield model_processor\n",
    "    \n",
    "    model = AutoModel.from_pretrained('intfloat/multilingual-e5-small')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-small')\n",
    "    model_processor = E5ModelProcessor(model, tokenizer, device=DEVICE)\n",
    "    yield model_processor\n",
    "    \n",
    "    model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "    model_processor = LabseModelProcessor(model, tokenizer, device=DEVICE)\n",
    "    yield model_processor\n",
    "    \n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    tokenizer = None\n",
    "    model_processor = MinilmModelProcessor(model, tokenizer, device=DEVICE)\n",
    "    yield model_processor\n",
    "\n",
    "    model = INSTRUCTOR('hkunlp/instructor-base')\n",
    "    tokenizer = None\n",
    "    model_processor = InstructorModelProcessor(model, tokenizer, device=DEVICE)\n",
    "    yield model_processor\n",
    "    \n",
    "    model = gensim.downloader.load('glove-twitter-25')\n",
    "    tokenizer = None\n",
    "    model_processor = GloveModelProcessor(model, tokenizer, device=DEVICE)\n",
    "    yield model_processor\n",
    "\n",
    "\n",
    "def get_dataset_metric():\n",
    "    dataset_processor = FloresDatasetProcessor()\n",
    "    metric = calculate_UDM\n",
    "    yield dataset_processor, metric, None\n",
    "    \n",
    "    dataset_processor = ParaphraserDatasetProcessor()\n",
    "    metric = calculate_PAR\n",
    "    yield dataset_processor, metric, None\n",
    "    \n",
    "    dataset_processor = ToxiDatasetProcessor()\n",
    "    metric = calculate_TOX\n",
    "    yield dataset_processor, metric, None\n",
    "    \n",
    "    # Ограничиваю 2000, иначе очень долго считать\n",
    "    dataset_processor = SummDatasetProcessor()\n",
    "    metric = calculate_SUM\n",
    "    yield dataset_processor, metric, 2000\n",
    "    \n",
    "    dataset_processor = MGPDatasetProcessor()\n",
    "    metric = calculate_MGP\n",
    "    yield dataset_processor, metric, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483d94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 250/250 [00:01<00:00, 131.43it/s]\n",
      "100%|███████████████████████████████████████| 7227/7227 [04:49<00:00, 24.93it/s]\n",
      "  2%|▊                                      | 752/37910 [00:57<47:37, 13.00it/s]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from time import time\n",
    "\n",
    "# Фиксирую случайность \n",
    "def seed_all(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "seed_all()\n",
    "    \n",
    "start_time = time()\n",
    "\n",
    "for model_processor in get_models_tokenizers_processors():\n",
    "    for dataset_processor, metric, k in get_dataset_metric():\n",
    "        if k is None:\n",
    "            k = 1e9\n",
    "        metric_result = metric(model_processor, dataset_processor, k)\n",
    "        \n",
    "        eval_time = time() - start_time\n",
    "        \n",
    "        with open('logs.txt', 'a') as logs:\n",
    "            log = f'model:{model_processor.__class__}; metric:{metric.__name__}; result:{metric_result}; eval_time:{eval_time}.\\n'\n",
    "            logs.write(log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
